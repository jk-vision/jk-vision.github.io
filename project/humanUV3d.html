<!doctype html>
<html lang="en">
  
<head>
    <!-- Meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- Page info -->
    <meta http-equiv="author" content="Meng-Yu Jennifer Kuo" />
    
    <!-- HTML Meta Tags -->
    <title>Learning 3D Human UV with Loose Clothing from Monocular Video</title>
    <meta name="description" content="Learning 3D Human UV with Loose Clothing from Monocular Video">

    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">

    <title>Learning 3D Human UV with Loose Clothing from Monocular Video</title>
  </head>

  <body>
    <!-- Bootstrap JS -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p" crossorigin="anonymous"></script>

    <div class="container-fluid my-5 mx-auto" style="max-width: 840px;">
        <div class="row">
            <h1 class="display-6 text-center">
                <b>Learning 3D Human UV with Loose Clothing from Monocular Video</b> 
            </h1>
        </div>

        <div class="row mt-2">
            <div class="fs-4 fw-light text-center text-secondary">
                VISAPP 2024
            </div>
        </div>

        <div class="row text-center mt-3 mx-auto" style="max-width: 640px;">
            <div class="col-md-4">
                <a href="https://jk-vision.github.io/">
                    <b>Meng-Yu Jennifer Kuo</b>
                 </a><sup>1</sup>
            </div>
            <div class="col-md-4">
                <a href="https://scholar.google.com/citations?user=-PsRtB_TuTQC&hl=en">
                    Jingfan Guo
                </a><sup>1</sup>
            </div>
            <div class="col-md-4">
                <a href="https://scholar.google.com/citations?user=4OCOer8AAAAJ&hl=ja">
                    Ryo Kawahara
                </a><sup>2</sup>
            </div>
        </div>
        
        <div class="row text-center mt-3 mx-auto">
            <div class="col-md-6"><sup>1</sup>University of Minnesota</div>
            <div class="col-md-5"><sup>2</sup>Kyushu Institute of Technology</div>
        </div>

        
        <div class="row">
            <div class="col-md-12 mt-5">
                <image src="./result/humanUV3d_result.png" width="100%"></image>
                &nbsp;
                <p class="text-center">Input video frames, recovered geometry, and dense UV in 3D space from different viewpoints.</p>
            </div>
        </div>

        <div class="my-5">
            <h2>Abstract</h2>
            <p class="text-justidy mt-3">
                We introduce a novel method for recovering a consistent and dense 3D geometry and appearance of a dressed person from a monocular video. Existing methods mainly focus on tight clothing and recover human geometry as a single representation. 
Our key idea is to regress the holistic 3D shape and appearance as a canonical displacement and albedo maps in the UV space, while fitting the visual observations across frames. 
Specifically, we represent the naked body shape by a UV-space SMPL model, and represent the other geometric details, including the clothing, as a shape displacement UV map. 
We obtain the temporally coherent overall shape by leveraging a differential mask loss and a pose regularization. 
The surface details in UV space are jointly learned in the course of non-rigid deformation with the differentiable neural rendering. Meanwhile, the skinning deformation in the garment region is updated periodically to adjust its residual non-rigid motion in each frame. We additionally enforce the temporal consistency of surface details by utilizing the optical flow. Experimental results on monocular videos demonstrate the effectiveness of the method.
Our UV representation allows for simple and accurate dense 3D correspondence tracking of a person wearing loose clothing. We believe our work would benefit applications including VR/AR content creation.
            </p>
        </div>

        <!-- <div class="my-5">
            <h2>Video</h2>
            <div class="text-center mt-3">
                <div style="position:relative;padding-top:56.25%;">
                    <iframe src="" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                </div>
            </div>
        </div> -->

        <div class="my-5">
            <h2>Resources</h2>
            <div class="row mt-4">
                <div class="col-md-12 text-center">
                    <ul class="nav nav-tabs nav-justified">
                        <li class="nav-item">
                            <a class="nav-link" href="https://www.scitepress.org/Link.aspx?doi=10.5220/0012414500003660">
                            <image src="./assets/humanUV3d_paper.png" height="120px">
                                <p class="lead">paper</p>
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="https://drive.google.com/file/d/1cORa0xt3iTKySo1CnXZg84XZhkOAmCXB/view?usp=sharing">
                            <image src="./assets/humanUV3d_poster.png" height="120px">
                                <p class="lead">poster</p>
                            </a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="row my-5">
            <h2>Citation</h2>
            <p>If you found this work useful, please consider citing us: </p>
            <div class="col-md-12 mt-3">

<pre>
@conference{visapp24,
author={Meng{-}Yu Kuo and Jingfan Guo and Ryo Kawahara},
title={Learning 3D Human UV with Loose Clothing from Monocular Video},
booktitle={Proceedings of the 19th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications - Volume 4: VISAPP},
year={2024},
pages={122-129},
publisher={SciTePress},
organization={INSTICC},
doi={10.5220/0012414500003660},
isbn={978-989-758-679-8},
issn={2184-4321},
} 
</pre>
            </div>
        </div>

        <!-- <div class="my-5">
            <h2>Acknowledgement</h2>
            <p>
                This work was in part supported by 
            </p>
        </div> -->

    </div>

  </body>
</html>